"""
Classes to help load, process, analyze and save electrode grid data after [wavetracker](https://github.com/tillraab/wavetracker) processing.

## Load all tracked fish of a single recording

`GridTracks()` loads all frequency tracks (and positions if applicable). Per default the fine spectrogram is not loaded and the verbosity is enabled.

Data: 
- `GridTracks.times`: Time array across recording time.
- `GridTracks.idx_v`: Index vector to access time array for given track ids.
- `GridTracks.ident_v`: Identity vector to access data arrays for a given track id.
- `GridTracks.fund_v`: Fundamental frequency tracks.
- `GridTracks.sign_v`: Powers of tracked frequency across 64 electrodes.
- `GridTracks.xpos`: x-coordinate of position estimates.
- `GridTracks.ypos`: y-coordinate of position estimates.
- `GridTracks.xpos_smth`: x-coordinate of smoothed position estimates.
- `GridTracks.ypos_smth`: y-coordinate of smoothed position estimates.
- `GridTracks.spec`: Coarse spectrogram.
- `GridTracks.fill_freqs`: Frequencies of the fine spectrogram.
- `GridTracks.fill_times`: Times of the fine spectrogram.
- `GridTracks.fill_spec_shape`: Shape of the fine spectrogram.
- `GridTracks.fill_spec`: Data of the fine spectrogram.
- `GridTracks.meta`: Start and stop of recording, needed for wavetracker processing.

Methods:
- `fill_powers()`: recompute powers of frequency tracks.
- `remove_nans()`: discard all unassigned frequency tracks.
- `remove_short()`: discard all frequency tracks below a given duration thresold.
- `remove_poor()`: discard all frequency tracks with below a tracking performance threshold.
- `positions()`: estimate the fish positions from the weighted mean powers.
- `interpolate()`: linearly interpolate frequency, power and position seperately.
- `smooth_positions()`: smooth position estimates using a Savitzky-Golay filter.
- `check_integrity()`: check if all arrays are the same length and fit onto the time vector.
- `save()`: save generated data arrays to a given path.
- `extract_ids()`: delete all data except data for the specified track ids.
- `freq_bandpass()`: bandpass-filter the frequency tracks.
- `plot_frequencies()`: plot frequency tracks onto specified axis.
- `plot_spectrogram()`: plot coarse spectrogram and frequency tracks.
- `plot_positions()`: plot track positions.

## Load a dyad of tracked fish

`Dyad()` loads a pair of tracks from a `GridTracks` object only containing overlapping data for pairwise analysis of frequency or position.

## Load a single tracked fish

`Monad()` loads a single track from a `GridTracks` object.
"""

import datetime
import glob
import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from IPython import embed
from modules.functions import find_closest, is_odd, kde1d, velocity2d
from modules.termcolors import TermColor as tc
from scipy.signal import butter, find_peaks, medfilt, savgol_filter, sosfiltfilt
from thunderfish import dataloader, powerspectrum
from tqdm import tqdm


class GridTracks:
    """
    Class to load, process and save electrode grid data as it is generated by the wavetracker algorithm (https://github.com/tillraab/wavetracker). Processing functions can be used independently but some may rely on others. All class methods are implemented in place, i.e. they modify the data included in the current class instance.

    Returns
    -------
    GridTracks : class instance
        Object with grid data and methods to process it.
    """

    def __init__(self, datapath, finespec=False, verbose=True):
        # set verbosity
        self.verbose = verbose
        self.tqdm_disable = False if self.verbose is True else True

        self.datapath = datapath
        self.dataroot, _ = os.path.split(self.datapath[:-1])
        self.finespec = finespec

        # load wavetracker output
        self.times = np.load(datapath + "times.npy", allow_pickle=True)
        self.meta = np.load(datapath + "meta.npy", allow_pickle=True)
        self.idx_v = np.load(datapath + "idx_v.npy", allow_pickle=True)
        self.spec = np.load(datapath + "spec.npy", allow_pickle=True)
        self.fund_v = np.load(datapath + "fund_v.npy", allow_pickle=True)
        self.sign_v = np.load(datapath + "sign_v.npy", allow_pickle=True)
        self.ident_v = np.load(datapath + "ident_v.npy", allow_pickle=True)
        self.ids = np.unique(self.ident_v[~np.isnan(self.ident_v)])

        # load datetime from recording date
        folder = self.datapath[:-1]
        rec_year, rec_month, rec_day, rec_time = os.path.split(
            os.path.split(folder)[-1]
        )[-1].split("-")

        rec_year = int(rec_year)
        rec_month = int(rec_month)
        rec_day = int(rec_day)

        try:
            rec_time = [
                int(rec_time.split("_")[0]),
                int(rec_time.split("_")[1]),
                0,
            ]
        except:
            rec_time = [
                int(rec_time.split(":")[0]),
                int(rec_time.split(":")[1]),
                0,
            ]
        rec_datetime = datetime.datetime(
            year=rec_year,
            month=rec_month,
            day=rec_day,
            hour=rec_time[0],
            minute=rec_time[1],
            second=rec_time[2],
        )

        self.datetimes = list(
            map(lambda x: rec_datetime + datetime.timedelta(seconds=x), self.times)
        )

        try:
            self.temp = np.load(datapath + "temp.npy", allow_pickle=True)
            self.light = np.load(datapath + "light.npy", allow_pickle=True)
        except FileNotFoundError:
            print(
                tc.warn("[ GridTracks.__init__ ]")
                + f" No temperature an light data found in directory {self.datapath}."
            )

        if self.finespec:
            self.fill_freqs = np.load(datapath + "fill_freqs.npy", allow_pickle=True)
            self.fill_times = np.load(datapath + "fill_times.npy", allow_pickle=True)
            self.fill_spec_shape = np.load(
                datapath + "fill_spec_shape.npy", allow_pickle=True
            )
            self.fill_spec = np.memmap(
                datapath + "fill_spec.npy",
                dtype="float",
                mode="r",
                shape=(self.fill_spec_shape[0], self.fill_spec_shape[1]),
                order="F",
            )

        try:
            self.xpos = np.load(datapath + "xpos.npy", allow_pickle=True)
            self.ypos = np.load(datapath + "ypos.npy", allow_pickle=True)
        except FileNotFoundError:
            print(
                tc.warn("[ GridTracks.__init__ ]")
                + f" No position estimations found in directory {self.datapath}"
            )
        try:
            self.xpos_smth = np.load(datapath + "xpos_smth.npy", allow_pickle=True)
            self.ypos_smth = np.load(datapath + "ypos_smth.npy", allow_pickle=True)
        except FileNotFoundError:
            print(
                tc.warn("[ GridTracks.__init__ ]")
                + f" No smoothed position estimations found in directory {self.datapath}"
            )
        try:
            # all variables that are kept empty for now
            self.num_el = None
            self.gridx = None
            self.gridy = None

            self.grid_rate = dataloader.fishgrid_samplerate(datapath)
            self.grid_spacings = dataloader.fishgrid_spacings(datapath)
            self.grid_grid = dataloader.fishgrid_grids(datapath)
        except FileNotFoundError as e:
            print(
                tc.warn("[ GridTracks.__init__ ]")
                + f" No grid metadata found in directory {self.datapath}"
            )

    def fill_powers(self, filename="traces-grid1.raw"):
        """
        Function to compute missing powers from sign_v.npy after manually correcting frequency tracks using the EODsorter.py GUI from the wavetracker. Creates a copy of the old signature vector, computes a new signature vector and loads it into the GridTracks instance.

        Parameters
        ----------
        filename : str, optional
            File name of the raw grid file located where the other grid data is, by default "traces-grid1.raw"

        Returns
        -------
        GridTracks.sign_v : 2d numpy array
            Corrected powers across all electrodes for the respective frequencies.
        """

        if len(self.ident_v) != len(self.sign_v):
            print(
                tc.err("[ GridTracks.fill_powers ]")
                + " sign_v and ident_v are not the same length. Data is either corrupted or already interpolated! Aborting ..."
            )
            return None

        samplerate = self.grid_rate
        path = self.datapath + filename
        raw = dataloader.open_data(path, -1, 60.0, 10.0)
        my_nfft = powerspectrum.nfft(samplerate, freq_resolution=1)

        if self.verbose:
            print(
                tc.succ("[ GridTracks.fill_powers ]") + " Updating signature vector ..."
            )

        for track_id in tqdm(self.ids, disable=self.tqdm_disable):

            # get index for id where signature vector has nans
            id_powers = self.sign_v[:, 0][self.ident_v == track_id]
            idxs = np.where(np.isnan(id_powers))[0]

            # get times for missing powers, i.e. where sign_v is nan
            times = self.times[self.idx_v[self.ident_v == track_id]][idxs]

            # convert times to indices for raw data by multiplying bt original sampling rate
            iois = times * samplerate

            # loop over raw sample points
            for ioi, idx in zip(iois, idxs):

                # get frequency for id at time point of ioi
                freq = self.fund_v[self.ident_v == track_id][idx]

                # loop over recording channels in raw data
                for channel in np.arange(np.shape(raw)[1]):

                    # calculate power spectrum for channel at ioi
                    freqs, powers = powerspectrum.psd(
                        raw[int(ioi - my_nfft / 2) : int(ioi + my_nfft / 2), channel],
                        ratetime=samplerate,
                        overlap_frac=0.9,
                        freq_resolution=1,
                    )

                    # select power for frequency that matches fundamental freq of track id most closely
                    power_sel = powers[find_closest(freqs, freq)]

                    # log transform
                    power_sel_log = powerspectrum.decibel(power_sel)

                    # write computed power to file
                    insert_idx = np.arange(len(self.sign_v))[self.ident_v == track_id][
                        idx
                    ]

                    self.sign_v[insert_idx, channel] = power_sel_log

        # do some checks
        try:
            backup_sign_v = np.load(
                self.datapath + "sign_v_backup.npy", allow_pickle=True
            )
            newlen = len(
                np.arange(len(self.sign_v[:, 0]))[~np.isnan(self.sign_v[:, 0])]
            )
            oldlen = len(
                np.arange(len(backup_sign_v[:, 0]))[~np.isnan(backup_sign_v[:, 0])]
            )
            if self.verbose:
                print(
                    tc.succ("[ GridTracks.fill_powers ]")
                    + f" {newlen-oldlen} powers added compared to sign_v_backup.npy"
                )
        except FileNotFoundError as e:
            if self.verbose:
                print(
                    tc.warn("[ GridTracks.fill_powers ]")
                    + " No backup sign_v found, comparing to self only."
                )

        old_sign_v = np.load(self.datapath + "sign_v.npy", allow_pickle=True)
        newlen = len(np.arange(len(self.sign_v[:, 0]))[~np.isnan(self.sign_v[:, 0])])
        oldlen = len(np.arange(len(old_sign_v[:, 0]))[~np.isnan(old_sign_v[:, 0])])
        if self.verbose:
            print(
                tc.succ("[ GridTracks.fill_powers ]")
                + f" {newlen-oldlen} powers added compared to old sign_v.npy"
            )

        # create backup of old and save new
        backup = self.datapath + "sign_v_backup.npy"
        if os.path.isfile(backup):
            # save sign_v to file
            np.save(self.datapath + "sign_v.npy", self.sign_v)
            if self.verbose:
                print(
                    tc.succ("[ GridTracks.fill_powers ]")
                    + " Backup signature vector found, saving and skipping backup."
                )
        else:
            # rename old sign vector to backup
            os.rename(self.datapath + "sign_v.npy", backup)
            np.save(self.datapath + "sign_v.npy", self.sign_v)
            if self.verbose:
                print(
                    tc.succ("[ GridTracks.fill_powers ]")
                    + " signature vector backup created"
                )

        try:
            self.sign_v = np.load(self.datapath + "sign_v.npy", allow_pickle=True)
            if self.verbose:
                print(
                    tc.succ("[ GridTracks.fill_powers ]")
                    + " New sign_v loaded into namespace"
                )
        except FileNotFoundError:
            print(
                tc.err("[ GridTracks.fill_powers ]")
                + " Error loading newly generated sign_v into namespace!"
            )
            return None

    def load_logger(self, filename="hobologger.csv"):
        """
        Load temperature and light data from a cleaned, upsampled hobologger file.

        Parameters
        ----------
        filename : str, optional
            Name of the hobologger file located in the dataroot directory, by default "hobologger.csv"

        Returns
        -------
        GridTracks.temp : numpy array
            Temperature in degrees Celsius for the recording.
        GridTracks.light : numpy array
            Light data in lux for the recording.
        """

        # load logger data
        self.logger = pd.read_csv(self.dataroot + "/" + filename)
        self.logger["date"] = pd.to_datetime(self.logger["date"])
        self.logger = self.logger.set_index("date")

        min_grid = self.datetimes[0].strftime("%Y-%m-%d %H:%M:%S")
        max_grid = self.datetimes[-1].strftime("%Y-%m-%d %H:%M:%S")

        start = self.logger.index.get_indexer([min_grid], method="nearest")[0]
        stop = self.logger.index.get_indexer([max_grid], method="nearest")[0]

        self.logger = self.logger.reset_index()
        self.temp = self.logger["temp_filt"][start:stop]
        self.light = self.logger["lux_filt"][start:stop]

        time = self.logger["date"][start:stop]
        self.logger_times = np.arange(len(time))

        if len(self.temp) == 0:
            print(
                tc.err("[ GridTracks.load_logger ]")
                + " No logger data found for this recording date."
            )
            del self.temp
            del self.light
            del self.logger_times
            del self.logger
            return None

        self.temp = np.interp(self.times, self.logger_times, self.temp)
        self.light = np.interp(self.times, self.logger_times, self.light)

    def q10_norm(self, normtemp=25, q10=1.6):
        """
        Normalize frequency traces by a Q10 value. WARNING: This will overwrite the frequency traces in the current class instance. If you call the GridTracks.save() function on normalized frequency traces, the non-normalized frequency traces will be overwritten.

        Parameters
        ----------
        normtemp : int, optional
            Temperature to norm fundamental frequencies to, by default 25
        q10 : float, optional
            Q10 value of the recorded species, by default 1.6

        Returns
        -------
        GridTracks.normtemp : float
            The temperature that the data is normalized to.
        GridTracks.q10 : float
            The Q10 value used to normalize.
        GridTracks.fund_v : numpy array
            The new, normalized frequencies.
        """
        if hasattr(self, "temp") == False:
            print(
                tc.err("[ GridTracks.q10_norm ]")
                + " Please provide temperature data before norming by Q10"
            )
            return None
        if hasattr(self, "xpos") == False:
            print(
                tc.warn("[ GridTracks.q10_norm ]")
                + " GridTracks instance has no position estimates. Compute position estimates before normalizing by Q10 or else position estimates will be wrong!"
            )
        else:
            self.normtemp = normtemp
            self.q10 = q10
            for track_id in self.ids:
                tmin = self.times[self.idx_v[self.ident_v == track_id]][0]
                tmax = self.times[self.idx_v[self.ident_v == track_id]][-1]

                index = np.arange(len(self.times))
                start, stop = (
                    index[self.times == tmin][0],
                    index[self.times == tmax][0] + 1,
                )

                temp = self.temp[start:stop]

                oldeod = self.fund_v[self.ident_v == track_id]
                neweod = oldeod + (
                    oldeod * (self.q10 % 1 * ((self.normtemp - temp) / 10))
                )
                self.fund_v[self.ident_v == track_id] = neweod

    def sex_ids(self, upper="m", thresh=740):
        """
        Estimates the sex of each tracked ID based on the maximum of the KDE of each fundamental frequency track (i.e. the estimated mode of a continuous distribution).

        Sex is determined by a species specific threshold and is only useful for species with a sexually dimorphic EODf. The threshold should be determined by plotting the frequency distribution of all individuals. E.g. for A. leptorhynchus, there is a dip in the frequency distribution that seperates the sexes.

        Parameters
        ----------
        upper : str, optional
            The sex of the individuals of higher EODf, by default "m" for A. leptorhynchus
        thresh : int, optional
            The frequency threshold seperating the sexes, by default 740 for A. leptorhynchus

        Returns
        -------
        GridTracks.sex : numpy array
            Sexes for each ID in the GridTracks.ids array.
        GridTracks.eodf : numpy array
            Computed resting EODf (i.e. estimated mode of each fishs EODf) that was used to assign the sex.
        """
        self.sex = []
        self.eodf = []

        for track_id in self.ids:
            fund = self.fund_v[self.ident_v == track_id]
            kde = kde1d(fund, bandwidth=0.3, resolution=100)
            eodf = kde[0][kde[1] == np.max(kde[1])][0]
            self.eodf.append(eodf)

            if upper == "m":
                if eodf > thresh:
                    self.sex.append("m")
                if eodf <= thresh:
                    self.sex.append("f")
            if upper == "f":
                if eodf > thresh:
                    self.sex.append("f")
                if eodf <= thresh:
                    self.sex.append("m")

        self.sex = np.asarray(self.sex)
        self.eodf = np.asarray(self.eodf)

    def remove_nans(self):
        """
        Removes all NANs, i.e. unassigned frequencies from the class instance.
        """

        self.idx_v = np.delete(self.idx_v, np.isnan(self.ident_v))
        self.fund_v = np.delete(self.fund_v, np.isnan(self.ident_v))
        self.sign_v = np.delete(self.sign_v, np.isnan(self.ident_v), axis=0)
        self.ident_v = np.delete(self.ident_v, np.isnan(self.ident_v))
        self.ids = np.delete(self.ids, np.isnan(self.ids))

        print(
            f"{tc.GREEN}{tc.BOLD}[ GridTracks.remove_nans ]{tc.END} Removed unassignes frequencies"
        )

    def remove_short(self, thresh):
        """
        Removes all ids and associated data that are tracked ofer a time that is shorter than the specified threshold.

        Parameters
        ----------
        thresh : float
            Minimum duration of time in seconds covered in a frequency track.
        """ """"""

        i = 0
        indicator_pos = False
        indicator_pos_smth = False

        for track_id in tqdm(self.ids, disable=self.tqdm_disable):
            times_tmp = self.times[self.idx_v[self.ident_v == track_id]]  # times for id
            duration = max(times_tmp) - min(times_tmp)

            # discard all tracks shorter than 1 hour
            if duration < thresh:
                self.idx_v = np.delete(self.idx_v, self.ident_v == track_id)
                self.fund_v = np.delete(self.fund_v, self.ident_v == track_id)
                try:
                    self.sign_v = np.delete(
                        self.sign_v, self.ident_v == track_id, axis=0
                    )
                except:
                    print(
                        tc.warn("[ GridTracks.remove_short ]")
                        + " Signature vector mismatch, you are working on uncleaned data."
                    )

                if hasattr(self, "xpos"):
                    self.xpos = np.delete(self.xpos, self.ident_v == track_id)
                    self.ypos = np.delete(self.ypos, self.ident_v == track_id)
                    if hasattr(self, "xpos_smth"):
                        self.xpos_smth = np.delete(
                            self.xpos_smth, self.ident_v == track_id
                        )
                        self.ypos_smth = np.delete(
                            self.ypos_smth, self.ident_v == track_id
                        )
                    else:
                        indicator_pos_smth = True
                else:
                    indicator_pos = True

                self.ident_v = np.delete(self.ident_v, self.ident_v == track_id)
                self.ids = np.delete(self.ids, self.ids == track_id)
                i += 1

        # Check if position data was found and indicate in terminal
        if indicator_pos:
            print(
                f"{tc.YELLOW}{tc.BOLD}[ GridTracks.remove_short ]{tc.END} No position data found."
            )

        if indicator_pos_smth:
            print(
                f"{tc.YELLOW}{tc.BOLD}[ GridTracks.remove_short ]{tc.END} No smoothed position data found."
            )

        if self.verbose:
            print(
                f"{tc.GREEN}{tc.BOLD}[ GridTracks.remove_short ]{tc.END} Removed {i} short tracks with threshold of {thresh} seconds."
            )

    def remove_poor(self, thresh):
        """
        Removes tracks below a specified track quality threshold.

        Parameters
        ----------
        thresh : float between 0 and 1
            Minimum percentage of track completedness for each tracked id.
        """

        i = 0
        for track_id in tqdm(self.ids, disable=self.tqdm_disable):
            # get min and max sampled time
            min_id = min(self.times[self.idx_v[self.ident_v == track_id]])
            max_id = max(self.times[self.idx_v[self.ident_v == track_id]])

            # get index for min and max
            start = np.where(self.times == min_id)
            stop = np.where(self.times == max_id)

            # get true times including non sampled
            times = self.times[int(start[0]) : int(stop[0])]

            # get sampled times and fundamental frequencies
            times_sampled = self.times[self.idx_v[self.ident_v == track_id]]

            # calculate tracking performance for id
            perf = len(times_sampled) / len(times)

            # discard all tracks that fall below the threshold
            if perf < thresh:
                self.idx_v = np.delete(self.idx_v, self.ident_v == track_id)
                self.fund_v = np.delete(self.fund_v, self.ident_v == track_id)
                self.sign_v = np.delete(self.sign_v, self.ident_v == track_id, axis=0)
                self.ident_v = np.delete(self.ident_v, self.ident_v == track_id)
                self.ids = np.delete(self.ids, self.ids == track_id)
                i += 1

        print(
            f"{tc.GREEN}{tc.BOLD}[ GridTracks.remove_poor ]{tc.END} Removed {i} tracks with performance threshold {thresh}"
        )

    def positions(self, num_el):
        """
        Estimates fish positions on the grid based on the powers of the tracked
        fundamental frequencies in the sign_v vector.

        Positions are estimated by weighting the mean position of n electrodes with the
        highest power by their respective power, i.e. the power weighted mean.

        DISCLAIMER: The implementation of this function currently only allows for position estimation on a square grid.

        Parameters
        ----------
        num_el : integer
            Number of grid electrodes used for position estimation.

        Returns
        -------
        GridTracks.num_el : integer
            Number of grid electrodes used for position estimation.
        GridTracks.xpos: numpy array
            x posiitons for each track ID
        GridTracks.ypos: numpy array
            y posiitons for each track ID

        """

        if len(self.ident_v) != len(self.sign_v):
            print(
                tc.err("[ GridTracks.positions ]")
                + " sign_v and ident_v are not the same length. Data is either corrupted or interpolated! Check array lengths. Aborting ..."
            )
            return None

        # create grid coordinates
        self.num_el = num_el
        self.gridx = []
        self.gridy = []
        grid_dist = self.grid_spacings[0][0]
        grid_dim = self.grid_grid[0]

        x_constructor = np.linspace(0, grid_dist * (grid_dim[0] - 1), grid_dim[0])
        for x_coord in x_constructor:
            y_constructor = np.ones(grid_dim[1]) * x_coord
            self.gridx.extend(x_constructor)
            self.gridy.extend(y_constructor)

        # empty lists for data
        x_pos = np.zeros(np.shape(self.ident_v))
        y_pos = np.zeros(np.shape(self.ident_v))
        ident_v_tmp = np.zeros(np.shape(self.ident_v))
        index = 0

        if self.verbose:
            print(
                f"{tc.GREEN}{tc.BOLD}[ GridTracks.positions ]{tc.END} Computing fish positions from {num_el} electrodes ..."
            )

        for track_id in tqdm(np.unique(self.ids), disable=self.tqdm_disable):
            # powers for id from sign vector
            powers = self.sign_v[self.ident_v == track_id]

            for idx in range(len(powers[:, 0])):

                # powers at a single point in time for single id
                mom_powers = powers[idx, :]

                # calculate max n powers
                ind = np.argpartition(mom_powers, -num_el)[-num_el:]
                max_powers = mom_powers[ind]

                # get respective coordinates
                x_maxs = np.array(self.gridx)[ind]
                y_maxs = np.array(self.gridy)[ind]

                # weighted mean
                x_wm = sum(x_maxs * max_powers) / sum(max_powers)
                y_wm = sum(y_maxs * max_powers) / sum(max_powers)

                # add to loop storage vector
                x_pos[index] = x_wm
                y_pos[index] = y_wm
                ident_v_tmp[index] = track_id
                index += 1

        # write to class data
        self.xpos = np.zeros(np.shape(self.ident_v))
        self.ypos = np.zeros(np.shape(self.ident_v))
        for track_id in self.ids:
            self.xpos[self.ident_v == int(track_id)] = x_pos[
                ident_v_tmp == int(track_id)
            ]
            self.ypos[self.ident_v == int(track_id)] = y_pos[
                ident_v_tmp == int(track_id)
            ]

    def interpolate(self, positions=True):
        """
        Tries to interpolate self.sign_v and self.fund_v so that they are the same length as the time array.
        """

        if (hasattr(self, "xpos") == False) & (all == True):
            print(
                tc.err("[ GridTracks.interpolate ]")
                + " No position vectors detected. Please compute the positions before interpolation."
            )
            return None

        elif (hasattr(self, "xpos")) | (all == False):
            if self.verbose:
                print(
                    f"{tc.GREEN}{tc.BOLD}[ GridTracks.interpolate ]{tc.END} Interpolating fund_v, sign_v, xpos, ypos..."
                )

            if positions == False:
                for track_id in tqdm(self.ids, disable=self.tqdm_disable):
                    # get min sampled time and max sampled time
                    min_id = min(self.times[self.idx_v[self.ident_v == track_id]])
                    max_id = max(self.times[self.idx_v[self.ident_v == track_id]])

                    # get index for min and max
                    start = np.where(self.times == min_id)
                    stop = np.where(self.times == max_id)

                    # get true times including non sampled
                    times_full = self.times[int(start[0]) : int(stop[0]) + 1]
                    times_sampled = self.times[self.idx_v[self.ident_v == track_id]]
                    fund_v_sampled = self.fund_v[self.ident_v == track_id]
                    fund_id_interp = np.interp(
                        times_full, times_sampled, fund_v_sampled
                    )

                    # jerry rig new index vector for the generated datapoints
                    start = np.where(self.times == min_id)
                    idx_v_full = np.arange(
                        int(start[0]), int(start[0]) + len(times_full)
                    )
                    ident_v_full = np.ones(len(idx_v_full), dtype=int) * int(track_id)

                    # delete old entries for respective ID from vectors
                    self.idx_v = np.delete(self.idx_v, self.ident_v == track_id)
                    self.fund_v = np.delete(self.fund_v, self.ident_v == track_id)
                    self.ident_v = np.delete(self.ident_v, self.ident_v == track_id)

                    self.idx_v = np.append(self.idx_v, idx_v_full)
                    self.fund_v = np.append(self.fund_v, fund_id_interp)
                    self.ident_v = np.append(self.ident_v, ident_v_full)
            else:
                for track_id in tqdm(self.ids, disable=self.tqdm_disable):
                    # get min sampled time and max sampled time
                    min_id = min(self.times[self.idx_v[self.ident_v == track_id]])
                    max_id = max(self.times[self.idx_v[self.ident_v == track_id]])

                    # get index for min and max
                    start = np.where(self.times == min_id)
                    stop = np.where(self.times == max_id)

                    # get true times including non sampled
                    times_full = self.times[int(start[0]) : int(stop[0]) + 1]
                    times_sampled = self.times[self.idx_v[self.ident_v == track_id]]

                    # get sampled times and fundamental frequencies
                    powers_sampled = self.sign_v[self.ident_v == track_id]
                    fund_v_sampled = self.fund_v[self.ident_v == track_id]
                    xpos_sampled = self.xpos[self.ident_v == track_id]
                    ypos_sampled = self.ypos[self.ident_v == track_id]

                    # interpolate signature matrix:
                    num_el = np.shape(powers_sampled)[1]
                    new_length = len(times_full)
                    newpowers = np.zeros(shape=(new_length, num_el))
                    for electrode in range(num_el):
                        powers = powers_sampled[:, electrode]
                        powers_interp = np.interp(times_full, times_sampled, powers)
                        newpowers[:, electrode] = powers_interp

                    # linear interpolation of the remaining vectors
                    fund_id_interp = np.interp(
                        times_full, times_sampled, fund_v_sampled
                    )
                    xpos_interp = np.interp(times_full, times_sampled, xpos_sampled)
                    ypos_interp = np.interp(times_full, times_sampled, ypos_sampled)

                    # jerry rig new index vector for the generated datapoints
                    start = np.where(self.times == min_id)
                    idx_v_full = np.arange(
                        int(start[0]), int(start[0]) + len(times_full)
                    )
                    ident_v_full = np.ones(len(idx_v_full), dtype=int) * int(track_id)

                    # delete old entries for respective ID from vectors
                    self.idx_v = np.delete(self.idx_v, self.ident_v == track_id)
                    self.sign_v = np.delete(
                        self.sign_v, self.ident_v == track_id, axis=0
                    )
                    self.fund_v = np.delete(self.fund_v, self.ident_v == track_id)
                    self.xpos = np.delete(self.xpos, self.ident_v == track_id)
                    self.ypos = np.delete(self.ypos, self.ident_v == track_id)
                    self.ident_v = np.delete(self.ident_v, self.ident_v == track_id)

                    # write new entries for respective ID to dict
                    self.idx_v = np.append(self.idx_v, idx_v_full)
                    self.sign_v = np.append(self.sign_v, newpowers, axis=0)
                    self.fund_v = np.append(self.fund_v, fund_id_interp)
                    self.xpos = np.append(self.xpos, xpos_interp)
                    self.ypos = np.append(self.ypos, ypos_interp)
                    self.ident_v = np.append(self.ident_v, ident_v_full)

                    test = len(self.times[self.idx_v[self.ident_v == track_id]]) == len(
                        self.fund_v[self.ident_v == track_id]
                    )

                    if test == False:
                        print(
                            f"{tc.RED}{tc.BOLD}[ GridTracks.interpolate ]{tc.END} Frequency array is not the same size as the time array!"
                        )
                    else:
                        pass

    def smooth_positions(self, params):
        """Clean up position estimations.

        Clean up position estimations using a combination of

        - velocity filtering : Exclude unrealistically fast traces, i.e. large outliers.
        - median filtering : Reduce small scale jitter, i.e. small outliers.
        - Savitzky-Golay filtering: Smooth resulting traces.

        Parameters
        ----------
        params : dict
            parameters included in the yaml configuration file for the preprocessing script.
        """
        vthresh = params["vthresh"]
        med_window = params["median_window"]
        smth_window = params["smoothing_window"]
        poly = params["smoothing_polyorder"]

        if self.verbose:
            print(
                f"{tc.GREEN}{tc.BOLD}[ GridTracks.smooth_positions ] {tc.END} Smoothing position tracks ..."
            )

        self.xpos_smth = np.zeros(len(self.xpos))
        self.ypos_smth = np.zeros(len(self.xpos))

        for track_id in tqdm(self.ids, disable=self.tqdm_disable):

            # get data
            time = self.times[self.idx_v[self.ident_v == track_id]]
            xpos = self.xpos[self.ident_v == track_id]
            ypos = self.ypos[self.ident_v == track_id]

            # get velocity
            v = velocity2d(time, xpos, ypos)

            # thresholding max velocity
            v[v > vthresh] = np.nan

            # index position arrays
            index = np.arange(len(xpos))
            nans = index[np.isnan(v)]

            # delete coordinates where velocity is too high
            xpos[nans] = np.nan
            ypos[nans] = np.nan

            # interpolate
            xpos = np.interp(time, time[~np.isnan(xpos)], xpos[~np.isnan(xpos)])
            ypos = np.interp(time, time[~np.isnan(ypos)], ypos[~np.isnan(ypos)])

            # median filter
            xpos = medfilt(xpos, kernel_size=med_window)
            ypos = medfilt(ypos, kernel_size=med_window)

            # savgol filter
            xpos = savgol_filter(xpos, smth_window, poly)
            ypos = savgol_filter(ypos, smth_window, poly)

            # write to class namespace
            self.xpos_smth[self.ident_v == track_id] = xpos
            self.ypos_smth[self.ident_v == track_id] = ypos

    def check_integrity(self):
        """Checks if all data arrays are the same length and if they fit appropriately onto the time vector.

        Preprocessing steps must be performed in an order that makes sense. Example: Position estimation will not work on a `sign_v` with missing powers, since position estimation requires a power datapoint for each of the 64 electrodes for each frequency in the fundamental frequencies of a single fish.
        In some cases, computations in the wrong orders can result in mismatches between the data, i.e. the GridTracks object becomes unusable. For the preprocessing steps, it is recommended to stick to the order that is used in the supplied preprocessing script. This method can be used to check they integrity of the dataset after performing preprocessing steps.
        """

        reflen = len(self.fund_v)  # reference length
        passed = True

        if len(self.ident_v) != reflen:
            passed = False
            print(
                tc.err("[ GridTracks.check_integrity ]")
                + " ident_v is not the same lengths as frequencies!"
            )

        if len(self.sign_v) != reflen:
            passed = False
            print(
                tc.err("[ GridTracks.check_integrity ]")
                + " powers are not the same lengths as frequencies!"
            )

        if len(self.xpos) != reflen:
            passed = False
            print(
                tc.err("[ GridTracks.check_integrity ]")
                + " xpos are not the same lengths as frequencies!"
            )

        if len(self.ypos) != reflen:
            passed = False
            print(
                tc.err("[ GridTracks.check_integrity ]")
                + " ypos are not the same lengths as frequencies!"
            )

        if len(self.xpos_smth) != reflen:
            passed = False
            print(
                tc.err("[ GridTracks.check_integrity ]")
                + " ypos are not the same lengths as frequencies!"
            )

        if len(self.ypos_smth) != reflen:
            passed = False
            print(
                tc.err("[ GridTracks.check_integrity ]")
                + " ypos are not the same lengths as frequencies!"
            )

        for track_id in self.ids:
            time = self.times[self.idx_v[self.ident_v == track_id]]
            fund = self.fund_v[self.ident_v == track_id]
            power = self.sign_v[self.ident_v == track_id]
            xpos = self.xpos[self.ident_v == track_id]
            ypos = self.xpos[self.ident_v == track_id]
            xpos_smth = self.xpos[self.ident_v == track_id]
            ypos_smth = self.xpos[self.ident_v == track_id]

            if len(time) != len(fund):
                passed = False
            if len(time) != len(power):
                passed = False
            if len(time) != len(xpos):
                passed = False
            if len(time) != len(ypos):
                passed = False
            if len(time) != len(xpos_smth):
                passed = False
            if len(time) != len(ypos_smth):
                passed = False

            if passed == False:
                print(
                    tc.err("[ GridTracks.check_integrity ]")
                    + " GridTracks instance contains time-data mismatches!"
                )
                return False

        if passed:
            return True

    def save(self, outputpath, check=True):
        """Saves all data to the specified directory.

        Optionally checks for integrity before saving.

        Parameters
        ----------
        outputpath : string
            The path to the output directory.
        check : bool, optional
            Enable or disable running an integrity check before saving, by default True.
        """

        def save_data(self):
            np.save(outputpath + "/times.npy", self.times)
            np.save(outputpath + "/meta.npy", self.meta)
            np.save(outputpath + "/idx_v.npy", self.idx_v)
            np.save(outputpath + "/fund_v.npy", self.fund_v)
            np.save(outputpath + "/sign_v.npy", self.sign_v)
            np.save(outputpath + "/ident_v.npy", self.ident_v)
            np.save(outputpath + "/spec.npy", self.spec)
            np.save(outputpath + "/xpos.npy", self.xpos)
            np.save(outputpath + "/ypos.npy", self.ypos)
            np.save(outputpath + "/xpos_smth.npy", self.xpos_smth)
            np.save(outputpath + "/ypos_smth.npy", self.ypos_smth)
            if self.finespec == True:
                np.save(outputpath + "/fill_freqs.npy", self.fill_freqs)
                np.save(outputpath + "/fill_times.npy", self.fill_times)
                np.save(outputpath + "/fill_spec_shape.npy", self.fill_spec_shape)
                np.save(outputpath + "/fill_spec.npy", self.fill_spec)
            if hasattr(self, "temp"):
                np.save(outputpath + "/temp.npy", self.temp)
                np.save(outputpath + "/light.npy", self.light)

        if len(glob.glob(outputpath + "*.raw")) > 0:
            print(
                tc.err("[ WARNING! ]")
                + " Specified outpout directory contains a raw file. Are you trying to overwrite raw data? Please specify a dedicated directory for processed data! Aborting ..."
            )
            return None
        else:
            if self.verbose:
                print(
                    f"{tc.GREEN}{tc.BOLD}[ GridTracks.save ]{tc.END} Saving data to {outputpath}"
                )

            if check:
                if self.check_integrity():
                    save_data(self)
            else:
                save_data(self)

    def extract_ids(self, ids):
        """Returns a class instance only containing data for the track ids specified in the `ids` argument.
        The time array remains untouched, only `fund_v`, `sign_v`. `ident_v` and position estimates are truncated.
        """

        def delete_id_data(self, track_id):
            """Flexibly deletes data for specified ids from the class instance namespace.
            Skips signature or position arrays if vectors are not found."""

            # check for length mismatch of power and frequency arrays. This can happen
            # if the signature vector is not interpolated after preprocessing.
            sign_mismatch_indicator = False
            if len(self.sign_v) != len(self.ident_v):
                sign_mismatch_indicator = True
                if self.verbose:
                    print(
                        f"{tc.YELLOW}{tc.BOLD}[ GridTracks.extract_ids ]{tc.END} sign_v and ident_v are not the same length. Skipped signature vector."
                    )

            try:
                self.sex = np.delete(self.sex, self.ids == track_id)
                self.eodf = np.delete(self.eodf, self.ids == track_id)
            except AttributeError:
                print(
                    tc.warn("[ GridTracks.extract_ids ]")
                    + " No resting eodf found, skipping r.eodf extraction."
                )

            self.idx_v = np.delete(self.idx_v, self.ident_v == track_id)
            self.fund_v = np.delete(self.fund_v, self.ident_v == track_id)

            # extracting signature vector only if same length as ident_v
            if sign_mismatch_indicator is False:
                self.sign_v = np.delete(self.sign_v, self.ident_v == track_id, axis=0)

            if hasattr(self, "xpos"):
                self.xpos = np.delete(self.xpos, self.ident_v == track_id)
                self.ypos = np.delete(self.ypos, self.ident_v == track_id)
                if hasattr(self, "xpos_smth"):
                    self.xpos_smth = np.delete(self.xpos_smth, self.ident_v == track_id)
                    self.ypos_smth = np.delete(self.ypos_smth, self.ident_v == track_id)
                else:
                    if self.verbose:
                        print(
                            f"{tc.YELLOW}{tc.BOLD}[ GridTracks.extract_ids ]{tc.END} No smoothed position data found."
                        )
            else:
                if self.verbose:
                    print(
                        f"{tc.YELLOW}{tc.BOLD}[ GridTracks.extract_ids ]{tc.END} No smootposition data found."
                    )
            self.ident_v = np.delete(self.ident_v, self.ident_v == track_id)
            self.ids = np.delete(self.ids, self.ids == track_id)

        if self.verbose:
            print(
                f"{tc.GREEN}{tc.BOLD}[ GridTracks.extract_ids ]{tc.END} Extracting IDs ..."
            )
        for track_id in self.ids:
            if int(track_id) not in ids:
                delete_id_data(self, track_id)

    def freq_bandpass(self, rate, flow, fhigh, order=2, eod_shift=False):
        """Bandpass filters the fundamental frequencies tracked by the wavetracker.

        Particularly useful for event detection of frequency modulations on a stereotyped time scale. Can shift the resulting filtered tracks back to the resting EODf of the respective track ID. This makes sense if the frequency traces are normalized by Q10 prior. The resting EODf is calculated by the maximum of the KDE of the frequency tracks of one track ID, i.e. the estimated mode.

        Parameters
        ----------
        rate : float
            Sampling rate of the frequency tracks.
        flow : float
            Lower cutoff frequency of the bandpass filter.
        fhigh : float
            higher cutoff frequency of the bandpass filter.
        order : int, optional
            Order of the bandpass filter, by default 2
        eod_shift : bool, optional
            To enable or disable shifting the resulting filtered data back up to the respective resting EODf determined by estimating the mode, by default False.
        """

        def bandpass_filter(data, rate, flow, fhigh, order=2):
            sos = butter(order, [flow, fhigh], btype="band", fs=rate, output="sos")
            y = sosfiltfilt(sos, data)
            return y

        if self.verbose:
            print(
                f"{tc.GREEN}{tc.BOLD}[ GridTracks.freq_bandpass ]{tc.END} Applying bandpass filter ..."
            )
        self.resting_eods = np.zeros(len(self.ids))
        # self.fund_v = np.zeros(len(self.fund_v))

        for track_id in self.ids:
            filtered = bandpass_filter(
                self.fund_v[self.ident_v == track_id], rate, flow, fhigh, order
            )
            if eod_shift:
                kde = kde1d(
                    self.fund_v[self.ident_v == track_id], bandwidth=0.3, resolution=100
                )
                resting = kde[0][kde[1] == np.max(kde[1])][0]
                filtered_shifted = filtered + resting
                self.fund_v[self.ident_v == track_id] = filtered_shifted
                self.resting_eods[self.ids == track_id] = resting
            else:
                self.fund_v[self.ident_v == track_id] = filtered

    def plot_freq(self, ax, title="", ids=None, annotate=True):
        """Plot frequency tracks onto a matplotlib axis object.

        Parameters
        ----------
        ax : matplotlib axis
            The axis to plot the tracks onto.
        title : str, optional
            A title for the plot, by default ""
        ids : list, optional
            Supply list of ids or, if None, plot all ids, by default None.
        annotate : bool, optional
            Enable or disable annotating each track with the track ID, by default True.
        """

        if self.verbose:
            print(
                f"{tc.GREEN}{tc.BOLD}[ GridTracks.plot_frequencies ] {tc.END}{title} Plotting frequency tracks ..."
            )

        if ids is None:
            ids = self.ids

        for track_id in ids:
            times_tmp = self.times[self.idx_v[self.ident_v == track_id]]
            fund_v_tmp = self.fund_v[self.ident_v == track_id]
            ax.plot(times_tmp, fund_v_tmp)
            if annotate:
                ax.annotate(int(track_id), xy=(times_tmp[0], fund_v_tmp[0]))
        ax.set_title(title, loc="left")

        return ax

    def plot_spec(self, ax, title="", ids=None, annotate=True):
        """Plots the spectrogram with overlayed tracked fundamental frequencies onto the specified axis.

        Plots all ids if none are specified. This will yield strange results if frequencies are filtered or q10-normalized prior to plotting!

        Parameters
        ----------
        ax : matplotlib axis object
            The axis to plot the spectrogram onto.
        title : str, optional
            A plot title, by default ""
        ids : list, optional
            List of ids to plot, plot all if None, by default None.
        annotate : bool, optional
            Enable or disable annotating each frequency track by its track ID, by default True.
        """
        if self.verbose:
            print(
                f"{tc.GREEN}{tc.BOLD}[ GridTracks.plot_spec ] {tc.END}{title} Plotting spectrogram ..."
            )

        spectra = self.spec

        ax.imshow(
            powerspectrum.decibel(spectra)[::-1],
            extent=[
                self.times[0],
                self.times[-1] + (self.times[1] - self.times[0]),
                0,
                2000,
            ],
            aspect="auto",
            vmin=-100,
            vmax=-50,
            alpha=0.8,
            cmap=sns.color_palette("Spectral_r", as_cmap=True),
            interpolation="gaussian",
        )

        self.plot_freq(ax, title, ids, annotate)
        ax.set_xlabel("time")
        ax.set_ylabel("frequency [Hz]")
        ax.set_ylim(400, 1000)

    def plot_pos(self, ax, title="", ids=None, smoothed=True, legend=True):
        """Plots the triangulated positions of the frequency tracks onto the specified axis.

        Parameters
        ----------
        ax : matplotlib axis object
            Matplotlib axis to plot the positions onto.
        title : str, optional
            Plot title, by default ""
        ids : list, optional
            Track ids to plot, plot all if None, by default None
        smoothed : bool, optional
            Enable or disable plotting the smoothed data, by default True
        legend : bool, optional
            Enable or disable plotting a legend, by default True
        """
        if self.verbose:
            print(
                f"{tc.GREEN}{tc.BOLD}[ GridTracks.plot_pos ] {tc.END} Plotting positions ..."
            )

        if ids is None:
            ids = self.ids

        if (hasattr(self, "xpos_smth") is False) & (smoothed is True):
            print(
                tc.err(
                    'No smoothed position vectors found. Compute smoothed position vectors using the function "Data.smth_positions()" first'
                )
            )
            return None
        elif smoothed is True:
            xpos_plt = self.xpos_smth
            ypos_plt = self.ypos_smth
        else:
            xpos_plt = self.xpos
            ypos_plt = self.ypos

        for track_id in ids:
            ax.plot(
                xpos_plt[self.ident_v == track_id],
                ypos_plt[self.ident_v == track_id],
                alpha=1,
                label=int(track_id),
            )
        ax.set_xlim(-10, 360)
        ax.set_ylim(-10, 360)

        if legend:
            ax.legend(bbox_to_anchor=(1.02, 1), loc="upper left", frameon=False)

        ax.scatter(self.gridx, self.gridy, marker=".", color="gray")
        ax.set_title(title, loc="left")
        ax.set_xlabel("X distance [mm]")
        ax.set_ylabel("Y distance [mm]")


class Dyad:
    def __init__(self, gridtracks, ids, verbose=False):

        # set verbosity
        self.verbose = verbose
        self.tqdm_disable = True if self.verbose is True else False

        self.id1 = int(ids[0])
        self.id2 = int(ids[1])

        fish_times = [
            gridtracks.times[gridtracks.idx_v[gridtracks.ident_v == self.id1]].tolist(),
            gridtracks.times[gridtracks.idx_v[gridtracks.ident_v == self.id2]].tolist(),
        ]

        time_shared = set(fish_times[0]).intersection(*fish_times[1:])

        self.overlap = True
        if len(time_shared) > 0:
            tmin, tmax = (np.min(list(time_shared)), np.max(list(time_shared)))
        else:
            self.overlap = False
            print(
                tc.err("[ Dyad.__init__ ]")
                + " Supplied identities do not share a common overlap!"
            )
            return None

        # get temp and light if exists
        if hasattr(gridtracks, "temp"):
            times_all = gridtracks.times
            indices_all = np.arange(len(times_all))
            start, stop = (
                indices_all[times_all == tmin][0],
                indices_all[times_all == tmax][0] + 1,
            )
            self.temp = gridtracks.temp[start:stop]
            self.light = gridtracks.light[start:stop]
        else:
            print(
                tc.warn("[ Dyad.__init__  ]")
                + " GridTracks instance has no temperature and light arrays."
            )

        times1 = fish_times[0]
        times2 = fish_times[1]
        indices1 = np.arange(len(times1))
        indices2 = np.arange(len(times2))
        start1, stop1 = indices1[times1 == tmin][0], indices1[times1 == tmax][0] + 1
        start2, stop2 = indices2[times2 == tmin][0], indices2[times2 == tmax][0] + 1

        self.startstop_id1 = [start1, stop1]
        self.startstop_id2 = [start2, stop2]
        self.times = np.sort(list(time_shared))

        start1, stop1 = self.startstop_id1[0], self.startstop_id1[1]
        start2, stop2 = self.startstop_id2[0], self.startstop_id2[1]

        self.fund_id1 = gridtracks.fund_v[gridtracks.ident_v == self.id1][start1:stop1]
        self.sign_id1 = gridtracks.sign_v[gridtracks.ident_v == self.id1, :][
            start1:stop1, :
        ]
        self.xpos_id1 = gridtracks.xpos[gridtracks.ident_v == self.id1][start1:stop1]
        self.ypos_id1 = gridtracks.ypos[gridtracks.ident_v == self.id1][start1:stop1]
        self.xpos_smth_id1 = gridtracks.xpos_smth[gridtracks.ident_v == self.id1][
            start1:stop1
        ]
        self.ypos_smth_id1 = gridtracks.ypos_smth[gridtracks.ident_v == self.id1][
            start1:stop1
        ]

        self.fund_id2 = gridtracks.fund_v[gridtracks.ident_v == self.id2][start2:stop2]
        self.sign_id2 = gridtracks.sign_v[gridtracks.ident_v == self.id2, :][
            start2:stop2, :
        ]
        self.xpos_id2 = gridtracks.xpos[gridtracks.ident_v == self.id2][start2:stop2]
        self.ypos_id2 = gridtracks.ypos[gridtracks.ident_v == self.id2][start2:stop2]
        self.xpos_smth_id2 = gridtracks.xpos_smth[gridtracks.ident_v == self.id2][
            start2:stop2
        ]
        self.ypos_smth_id2 = gridtracks.ypos_smth[gridtracks.ident_v == self.id2][
            start2:stop2
        ]

        # calculate frequency and position difference arrays
        self.dfund = abs(self.fund_id2 - self.fund_id1)
        xdiff = abs(self.xpos_smth_id1 - self.xpos_smth_id2)
        ydiff = abs(self.ypos_smth_id1 - self.ypos_smth_id2)
        self.dpos = np.sqrt(xdiff**2 + ydiff**2)

        if is_odd(len(self.times)) is False:

            self.startstop_id1[1] = self.startstop_id1[1] - 1
            self.startstop_id2[1] = self.startstop_id2[1] - 1

            self.times = self.times[:-1]
            if hasattr(self, "temp"):
                self.temp = self.temp[:-1]
                self.light = self.light[:-1]

            self.fund_id1 = self.fund_id1[:-1]
            self.sign_id1 = self.sign_id1[:-1, :]
            self.xpos_id1 = self.xpos_id1[:-1]
            self.ypos_id1 = self.ypos_id1[:-1]
            self.xpos_smth_id1 = self.xpos_smth_id1[:-1]
            self.ypos_smth_id1 = self.ypos_smth_id1[:-1]

            self.fund_id2 = self.fund_id2[:-1]
            self.sign_id2 = self.sign_id2[:-1, :]
            self.xpos_id2 = self.xpos_id2[:-1]
            self.ypos_id2 = self.ypos_id2[:-1]
            self.xpos_smth_id2 = self.xpos_smth_id2[:-1]
            self.ypos_smth_id2 = self.ypos_smth_id2[:-1]

            self.dpos = self.dpos[:-1]
            self.dfund = self.dfund[:-1]


class Monad:
    """Extracts frequency, position and power arrays from a GridTracks instance
    for a single track ID."""

    def __init__(self, gridtracks, track_id, verbose=False):

        self.verbose = verbose
        self.id = int(track_id)
        self.times = gridtracks.times[gridtracks.idx_v[gridtracks.ident_v == self.id]]
        self.fund = gridtracks.fund_v[gridtracks.ident_v == self.id]
        self.sign = gridtracks.sign_v[gridtracks.ident_v == self.id, :]
        self.xpos = gridtracks.xpos[gridtracks.ident_v == self.id]
        self.ypos = gridtracks.ypos[gridtracks.ident_v == self.id]
        self.xpos_smth = gridtracks.xpos_smth[gridtracks.ident_v == self.id]
        self.ypos_smth = gridtracks.ypos_smth[gridtracks.ident_v == self.id]

        # get temp and light if exists
        if hasattr(gridtracks, "temp"):
            times_all = gridtracks.times
            indices_all = np.arange(len(times_all))
            tmin, tmax = self.times[0], self.times[-1]
            start, stop = (
                indices_all[times_all == tmin][0],
                indices_all[times_all == tmax][0] + 1,
            )
            self.temp = gridtracks.temp[start:stop]
            self.light = gridtracks.light[start:stop]
        else:
            print(
                tc.warn("[ Monad.__init__  ]")
                + " GridTracks instance has no temperature and light arrays."
            )

    def clip(self, min, max):
        """Clips the monad based on a start and stop time."""

        indices = np.arange(len(self.times))
        start = indices[self.times == min][0]
        stop = indices[self.times == max][0]

        self.times = self.times[start:stop]
        if hasattr(self, "temp"):
            self.temp = self.temp[start:stop]
            self.light = self.light[start:stop]
        self.fund = self.fund[start:stop]
        self.sign = self.sign[start:stop, :]
        self.xpos = self.xpos[start:stop]
        self.ypos = self.ypos[start:stop]
        self.xpos_smth = self.xpos_smth[start:stop]
        self.ypos_smth = self.ypos_smth[start:stop]


class Collective:
    """Creates a collective where n individuals overlap in frequency and position data.
    Returns None if supplied ids do not overlap. The collective is a list of Monad instances that are cut to match in size and can be called by indexing `Collective.monads[index]`."""

    def __init__(self, gridtracks, ids, thresh=1, verbose=False):
        self.verbose = verbose
        self.ids = ids
        self.fish = [Monad(gridtracks, fish_id) for fish_id in ids]

        # get overlap
        fish_times = [self.fish[i].times.tolist() for i in range(len(ids))]
        time_shared = set(fish_times[0]).intersection(*fish_times[1:])

        # check if overlap
        self.overlap = True
        if len(time_shared) > thresh:
            tmin, tmax = (np.min(list(time_shared)), np.max(list(time_shared)))
            for i in range(len(ids)):
                self.fish[i].clip(tmin, tmax)
            if self.verbose == True:
                print(
                    tc.succ("[ Collective.__init__ ]")
                    + " Collective created succesfully!"
                )
        else:
            self.overlap = False
            print(
                tc.err("[ Collective.__init__ ]")
                + " Supplied identities do not share a common overlap!"
            )

    def plot_pos(self, ax, title="", smoothed=True, legend=True):
        for i, track_id in enumerate(self.ids):
            if smoothed:
                ax.plot(self.fish[i].xpos_smth, self.fish[i].ypos_smth, label=track_id)
            else:
                ax.plot(self.fish[i].xpos, self.fish[i].ypos, label=track_id)
        ax.set_xlabel("x coordinate [cm]")
        ax.set_xlabel("y coordinate [cm]")
        ax.set_title(title)
        if legend:
            ax.legend(bbox_to_anchor=(1.02, 1), loc="upper left", frameon=False)

    def plot_freq(self, ax, title="", annotate=True):
        for i, track_id in enumerate(self.ids):
            ax.plot(self.fish[i].times, self.fish[i].fund, label=track_id)
            if annotate:
                ax.annotate(track_id, xy=(self.fish[i].times[0], self.fish[i].fund[0]))
        ax.set_title(title, loc="left")
        ax.set_xlabel("time [s]")
        ax.set_ylabel("frequency[Hz]")


class ListRecordings:
    """
    Lists subdiretories of data recordings in a given root directory to iterate over. Directory names specified as strings in the exclude list are ignored (e.g. directories containing metadata, etc.).
    """

    def __init__(self, path, exclude=[], verbose=False):

        # set correct paths and ids based on script setup parameters
        self.verbose = verbose
        self.dataroot = path
        self.exclude = exclude
        self.recordings = []

        # create list of recordings in dataroot
        for recording in os.listdir(self.dataroot):
            if os.path.isdir(os.path.join(self.dataroot, recording)):
                if recording not in self.exclude:
                    self.recordings.append(recording)

        if self.verbose:
            print(
                tc.succ("[ ListRecordings.__init__ ]")
                + f" {len(self.recordings)} found in {self.dataroot}."
            )
